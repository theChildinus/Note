<!-- TOC -->

- [简历相关](#简历相关)
    - [项目1](#项目1)
        - [Serviceability Agent](#serviceability-agent)
    - [项目2](#项目2)
    - [项目3](#项目3)
- [数据结构](#数据结构)
    - [红黑树](#红黑树)
    - [B/B+树](#bb树)
    - [epool libevent (异步I/O)](#epool-libevent-异步io)
    - [布隆过滤器](#布隆过滤器)
    - [字典树 AC自动机 fail节点 KMP](#字典树-ac自动机-fail节点-kmp)
- [数据库](#数据库)
    - [数据库存储过程、触发器](#数据库存储过程触发器)
    - [数据库范式](#数据库范式)
    - [ACID](#acid)
    - [并发一致性问题](#并发一致性问题)
    - [封锁](#封锁)
    - [隔离级别](#隔离级别)
    - [多版本并发控制](#多版本并发控制)
    - [数据库锁机制](#数据库锁机制)
        - [SQL语句锁实例分析](#sql语句锁实例分析)
    - [存储引擎](#存储引擎)
        - [InnoDB](#innodb)
        - [MyISAM](#myisam)
    - [数据库索引](#数据库索引)
        - [数据库索引分类](#数据库索引分类)
        - [索引失效、优缺点、优化](#索引失效优缺点优化)
        - [索引实现](#索引实现)
        - [聚簇索引和非聚簇索引](#聚簇索引和非聚簇索引)
    - [切分](#切分)
        - [水平切分](#水平切分)
        - [垂直切分](#垂直切分)
    - [视图](#视图)
    - [Redis](#redis)
        - [数据结构和对象](#数据结构和对象)
- [Linux](#linux)
    - [I/O 模式](#io-模式)
        - [阻塞I/O](#阻塞io)
        - [非阻塞I/O](#非阻塞io)
        - [I/O复用](#io复用)
        - [信号驱动I/O](#信号驱动io)
        - [异步I/O](#异步io)
        - [对比](#对比)
    - [内存管理](#内存管理)
        - [Buddy分配算法](#buddy分配算法)
        - [吞吐和响应](#吞吐和响应)
        - [硬链接和软链接](#硬链接和软链接)
- [其他](#其他)
    - [SIP协议](#sip协议)
    - [Web请求](#web请求)
    - [GET 和 POST 区别](#get-和-post-区别)
    - [Cookie 和 Session](#cookie-和-session)
    - [数字认证](#数字认证)
    - [路由分组转发](#路由分组转发)
    - [Reactor模式](#reactor模式)

<!-- /TOC -->

> 知识点总结

# 简历相关

遇到过的问题：

- 如何让 HotSpot 中已有的 Serviceability Agent 应用到 Volatility框架中
- 对JVM内存布局不了解
- 栈的生长过程，栈帧与栈帧之间的关系
- 缓冲区溢出过程中，栈的生长方向，数据的拷贝方向，溢出前后栈的信息变化

## 项目1

项目介绍：物联网服务运行时保障系统 是基于虚拟机入侵检测技术的运行时监控、恢复系统，实现了对 Linux虚拟机中正在运行的服务程序 进行运行时监控和处理反馈的功能，假设这样一个场景，当网络数据、串口数据不再安全可信时，我们还可以分析内存去判断数据的真实性，所以我在这个项目中主要负责对Linux虚拟机中 正在运行的服务程序 进行内存获取和分析，首先，由于服务程序是运行在Linux虚拟机中，在内存获取部分我使用了 Volatility 内存取证框架和LibVMI内存自省插件获取服务程序内存，其次，在内存分析部分 借助 Serviceability Agent 解析出Java进程及JVM虚拟机栈信息等，最后我还针对缓冲区溢出这种常见的攻击方式进行内存分析，实现了实时获取攻击前后函数调用关系变化，为系统检测模块后续分析提供依据

LibVMI库可以帮助我们通过 `System.map`（符号是指函数名，全局变量等，符号表记录着这些符号在内存中的虚拟地址）获取内核符号的虚拟地址，并找到对应的页表，通过页表找到数据页返回，即内存数据

`Volatility` 框架获取虚拟机中进程内存，需要两个信息，目标进程的逻辑地址 和 进程描述符的结构，前者标识了目标进程在内存中的逻辑位置，后者告诉我们进程运行的全部信息，这两个信息分别由 `System.map` 和 `module.dwarf` 提供，后一个文件是通过 `kernel-header` 生成的

这样我们就可以开始获取到虚拟机内所有进程的信息了

Java服务运行时 在Linux系统内统一的进程名为 java，Linux中进程是以链表的形式保存的，我们遍历进程链表，就可以找到进程名为 java 的进程了

对于任何一个Java程序 我们可以使用 jstack/jmap 等命令获取Java程序的堆栈信息，这些命令被封装在了 `Serviceability Agent` 中，它是 `HotSpot VM` 的调试工具，这个包中定义好了 `HotSpot VM` 中的一些Java类，比如Java线程类，栈帧类，这就方便了我们去分析Java程序中的堆栈信息

但是Volatility是用Python开发实现的，所以我们需要一个工具，让Python执行sa.jar包，即JPype工具，另外我们还需要用虚拟机中的KVM虚拟机中的JVM的信息去替换SA初始化需要的信息（这些信息包括共享库名称 - `task_struct.mm` 抽象并描述了Linux视角下管理进程地址空间的所有信息，共享库起始地址，所有的线程id - `thread_group`），这些信息正好是Volatility可以获取到的

替换掉之后，我们调用自己重新打包的 `sa-jdi.jar` 中的获取线程地址的方法 就是KVM虚拟机中的java程序的线程地址，在sa.jar包中，我们根据指定的线程名，遍历子线程列表，找到虚拟机中该线程的实例对象，可以获到获得虚拟机栈的栈顶地址，由于当前栈帧的值就是上一帧的地址，通过遍历获取栈底栈帧的FP地址，这样我们就可以自底向上分析虚拟机栈了

在Volatility中，把当前虚拟机栈的内存全部读出来，从 `fp - 48` 的位置就可以获取到方法栈帧中的参数，局部变量，局部对象引用等信息

### Serviceability Agent

ptrace系统调从名字上看是用于进程跟踪的，它提供了父进程可以观察和控制其子进程执行的能力，并允许父进程检查和替换子进程的内核镜像(包括寄存器)的值。

其基本原理是: 当使用了ptrace跟踪后，所有发送给被跟踪的子进程的信号(除了SIGKILL)，都会被转发给父进程，而子进程则会被阻塞，这时子进程的状态就会被系统标注为TASK_TRACED。而父进程收到信号后，就可以对停止下来的子进程进行检查和修改，然后让子进程继续运行。  

[Serviceability Agent](https://yq.aliyun.com/articles/20231)

在sa-jdi源码中 所有的工具类中都会启动一个 `BugSpotAgent`，在BugSpot的初始化过程中会调用 `setupDebugger` 和 `setupVM` 构造了目标VM的本机表示，通过源码分析，我们需要从这两个方法入手，替换 `setupDebugger` 初始化时的三个native方法，`attach0`，`lookupByName0` 和 `readBytesFromProcess0`  我们用Volatility获取的信息替换

- attach0：初始化VM需要，的共享库名，共享库地址，子线程ID
- lookupByName0：得到符号在内存中的地址，根据库名和符号名称在所有的共享库中遍历，找到符号偏移
- readBytesFromProcess0：得到从某地址开始指定长度的内存字节

`Serviceability Agent` 的实现原理是使用 Linux 的 `/proc` 和 `ptrace`，SA的基类是Tool，该方法会 `new BugSpotAgent()`，调用 `attach` 方法 到指定PID的VM上，在 `attach` 方法中会 调用两个方法：`setupDebugger()` 和 `setupVM()`

`setupDebugger` 会根据不同平台来设置debugger，Linux平台下，`setupDebuggerLinux` 中：

1. 设置函数库文件名 `{ "libjvm.so", "libjvm_g.so", "gamma_g" }`
2. new一个 `LinuxDebuggerLocal`
3. 调用 `LinuxDebuggerLocal` 的 `attach` 方法
4. `attach` 方法中调用了 `attach0` 方法
5. 在 `attach0` 中：
   - attach到目标进程 底层使用 linux 的 `ptrace`，**目的是为了读取目标进程的库文件信息和符号表**
   - 填充ps_prochandle
   - 读取目标进程的库文件信息和符号表 `read_lib_info`
6. 在 `read_lib_info` 方法中
   - 打开 `/proc/[pid]/maps`
   - 获取库文件信息
   - 添加库文件和符号表信息

`setupVM` 中

1. 构建HotSpotTypeDataBase
   - HotSpotTypeDataBase 存储了目标VM上的类型信息
2. 从目标VM获取原生类型大小并设置
3. 构建目标VM的本机表示，启动成功

我们要做的事情是：

- `setupDebugger()` 阶段，需要通过 `ptrace` 到目标进程上去获取目标进程的子线程、共享库文件和符号表，这样就可以获取到 HotSpotVM 中线程、变量、常量的地址，通过本地方法 `lookupByName0()` 实现，这个方法可以通过 Volatility 读共享库的方法实现替换
- `setupVM()` 阶段，通过 `/proc/[pid]/maps` 读取 elf 文件，也可以通过一些 VM 提供的元信息（`VMTypeEntry`，`VMStructEntry`，`VMIntConstantEntry`，`VMLongConstantEntry`）使用 `ptrace` 获取变量的地址，读取具体变量值的过程中，调用本地方法 `readBytesFromProcess0()` 完成，这个方法可以利用Volatility 提供的读内存的方法实现替换

libVMI 获取内核符号的流程

1. 应用程序请求查看内核符号
2. libvmi通过系统的System.map获取内核符号的虚拟地址
3. 找到虚拟地址所对应的内核页目录，并获取对应的页表
4. 通过页表找到正确的数据页
5. 数据页被返回给libvmi
6. libvmi将数据返回给vmi应用程序

`jstack` Dynamic Attach：

允许外部进程在HotSpot中启动线程，然后可以使用该线程启动代理以在该HotSpot中运行，并将有关HotSpot状态的信息发送回外部进程。这就涉及到进程间通信的问题，Linux中常用的方式为：信号机制 - 首先external process会先发送一个SIGQUIT信号给target VM process，target VM会创建一个Attach Listener线程；然后Attach Listener线程会通过Unix domain socket与external process建立连接，之后就可以基于这个socket进行通信了。

## 项目2

遇到的问题：

- libevent库如何使用
- 如何给页面编号， 对于每个HTML 页面而言，解析得到的URL中存在有效页面和无效页面，我们不能在这时对页面进行编号，因为对无效页面的编号会影响PageRank的计算，所以我们先把访问成功的页面和编号添加到 HashMap中，把URL关系写入临时文本，等待所有URL处理完，统一将临时文本中的URL替换为编号
- 而且在一个页面中存在一对连接关系出现多次的情况，在处理页面的过程中也许要去重

项目介绍：网站页面分析这个项目主要目的是爬取网站页面内容，提取URL，构建页面与页面之间的连接网络，最后根据pageRank算法计算出pk值前十的页面
在这个项目中我主要负责爬虫模块的开发，实现的主要流程是 添加定时事件查看 URL队列，提取URL，使用 BloomFilter 去重判断页面是否已经被抓取过，如果没有，DNS解析，建立网络连接，并添加写事件和读事件，在写事件中会发送HTTP请求，当连接数据到达触发读事件，使用AC自动机提取URL，添加到 URL 队列中

使用 AC 自动机而不是用 正则表达式是因为 Linux C Regex 库 只提供贪婪匹配，不支持非贪婪匹配，当匹配成功时会继续尝试向后匹配，看有没有更长的字符串，我们使用AC自动机就可以实现非贪婪匹配

Socket编程流程

- 服务器调用 `socket()`、`bind()`、`listen()` 完成初始化后，调用 `accept()` 阻塞等待，处于监听端口的状态
- 客户端调用 `socket()` 初始化后，调用 `connect()` 发出SYN段并阻塞等待服务器应答，服务器应答一个SYN-ACK段，客户端收到后从 `connect()` 返回，同时应答一个ACK段，服务器收到后从 `accept()` 返回。

connect (套接字默认阻塞) 出错返回的情况：

- 调用connect时内核发送一个SYN，若无响应则等待6s后再次发送一个，仍无响应则等待24s再发送一个，若总共等了75s后仍未收到响应则返回ETIMEDOUT错误；
- 若对客户的SYN的响应是RST，则表示该服务器主机在我们指定的端口上面没有进程在等待与之连接，例如服务器进程没运行，客户收到RST就马上返回ECONNREFUSED错误；
- 若客户发出的SYN在中间的某个路由上引发了一个“destination unreachable”（目的不可达）ICMP错误，客户主机内核保存该消息，并按1中所述的时间间隔发送SYN，在某个规定的时间（4.4BSD规定75s）仍未收到响应，则把保存的ICMP错误作为EHOSTUNREACH或ENETUNREACH错误返回给进程。

若 connect 失败，则该套接字不可用，必须关闭，我们不能对这样的套接字再次调用connect函数，在每次connect失败后，都必须close当前套接字并重新调用socket

## 项目3

项目介绍：个人博客系统是我个人的一个学习项目，通过使用Spring MVC搭建一个简单的博客系统，实现了用户和博客文章的增删改查这些基本功能，学习了Spring MVC开发的基本流程，开发流程分为以下几步：

- 构建Spring基本开发环境，使用Maven导入需要用的jar包
- 在web.xml 中添加一个servlet，用于拦截请求，并交给Spring MVC后台控制器处理请求（Model-java Bean，view-页面展示，controller-处理页面请求），在spring.xml中 添加视图解释器，用于返回视图
- 添加用户请求的controller类，RequestMapping注解定义请求隐射 return "index" 接收到访问请求后返回首页
- 配置Tomcat，导出war包启动验证是否可以访问首页
- 然后配置数据库，使用IDEA工具自动生成关于数据表的Java Bean，在spring.xml 中添加jpa配置，定义JPA操作，新建关于用户博客的Repository 继承 JpaRepository 在这里定义操作数据库的方法
- 开始编写业务逻辑：
  - **增**：GET请求跳转到添加用户管理页面，管理页面上点击添加提交后会触发POST请求，传递过来一个Entity对象，里面包含信息，通过Repository.saveAndFlush写入数据库，重定向到管理页面返回
  - **删**：接收到GET请求，PathVariable收集url的变量，使用Repository删除指定id的用户，刷新数据库，重定向到管理页面返回
  - **改**：接受到GET请求，PathVariable收集url的变量，调用Repository的findOne方法，获取数据后返回到页面上展示，页面上修改提交后会触发POST请求，传递一个Entity对象，通过Repository.flush写入数据库，重定向到管理页面返回
  - **查个人**：接收到GET请求，PathVariable收集url的变量，调用Repository的findById方法访问到指定用户信息，modelMap.addAttribute添加到页面上返回
  - **查所有**：接受到GET请求，调用Repository的findAll方法，获取到数据后，通过modelMap.addAttribute添加到页面上返回

GET 用于获取资源，而 POST 用于传输实体主体。GET 的参数是以查询字符串出现在 URL 中，而 POST 的参数存储在实体主体

Servlet是一个特殊的Java程序，它运行于服务器的JVM中，能够依靠服务器的支持向浏览器提供显示内容。JSP本质上是Servlet的一种简易形式，JSP会被服务器处理成一个类似于Servlet的Java程序，可以简化页面内容的生成。Servlet和JSP最主要的不同点在于，Servlet的应用逻辑是在Java代码中，并且完全从表示层中的HTML分离开来。而JSP的情况是Java和HTML可以组合成一个扩展名为.jsp的文件

# 数据结构

## 红黑树

首先红黑树是不符合AVL树的平衡条件的，即每个节点的左子树和右子树的高度最多差1的二叉查找树。但是提出了为节点增加颜色，红黑是用非严格的平衡来换取增删节点时候旋转次数的降低，任何不平衡都会在三次旋转之内解决，而AVL是严格平衡树，因此在增加或者删除节点的时候，根据不同情况，旋转的次数比红黑树要多。所以红黑树的插入效率更高

红黑树5个约束

- 每个节点或是红色的，或是黑色的。
- 根节点是黑色的。
- 每个叶节点（NULL）是黑色的。
- 如果一个节点是红色的，则它的两个孩子节点都是黑色的。（不能有两个父子节点都为红）
- 对每个节点，从该节点到其所有后代叶节点的简单路径上，均包含相同数目的黑色节点。

插入的几种情况，插入节点必为红节点

- 父黑 直接插入
- 父红 叔红
  - 变父节点为黑，叔节点为黑，祖父节点为红，当前节点指向祖父节点
- 父红 叔黑 插入节点是父的右节点
  - 父节点为新的当前结点，新当前结点为支点左旋
- 父红 叔黑 插入节点是父的左节点
  - 父节点为黑 祖父节点为红 以祖父节点为支点右旋

删除的几种情况

[参考](https://github.com/julycoding/The-Art-Of-Programming-By-July/blob/master/ebook/zh/03.01.md)

只针对删除黑色节点才有修复，思路是：

- 把父亲节点另一边（即删除节点的兄弟树）其中一个节点弄成红色，也少一个黑色
- 或者把另一边多的黑色节点转过来一个

- 当前结点是红+黑色，直接把当前结点染成黑色，结束此时红黑树性质全部恢复。
- 当前结点是黑+黑且是根结点， 解法：什么都不做，结束。

**情况1**：兄弟节点为红，那么父节点和兄弟节点的子节点为黑

- 父变红，兄变黑，左旋转父节点，重新进入算法

**情况2**：兄弟节点为黑，兄弟节点的两个子节点也为黑

- 兄弟节点变为红色，父节点到下面的所有路径都少了一个黑节点，父节点作为当前节点，重新进入算法

**情况3**：兄弟节点为黑，兄弟的左为红，右为黑

- 把兄弟结点染红，兄弟左子结点染黑，之后再在兄弟结点为支点解右旋，之后重新进入算法，此是把当前的情况转化为情况4

**情况4**：兄弟节点为黑，兄弟的右为红，左为任意

- 把兄弟结点染成当前结点父结点的颜色，把当前结点父结点染成黑色，兄弟结点右子染成黑色，之后以当前结点的父结点为支点进行左旋，此时算法结束

## B/B+树

B Tree 指的是 Balance Tree，也就是平衡多路查找树，一颗m阶的B_TREE或是一颗空树，或者是满足下列条件的m叉树：

- 树中每个结点最多有m个孩子结点；
- 若根结点不是叶子节点，则根结点至少有2个孩子结点；
- 除根结点外，其它结点至少有(m/2的上界)个孩子结点；
- 所有的叶结点都在同一层上，并且不带信息（可以看作是外部结点或查找失败的结点，实际上这些结点不存在，指向这些结点的指针为空）。

B+ Tree 是基于 B Tree 和叶子节点顺序访问指针进行实现，它具有 B Tree 的平衡性，并且通过顺序访问指针来提高区间查询的性能。

B+Tree是应文件系统所需而产生的一种B_TREE树的变形树。一棵m阶的B+树和m阶的B_TREE的差异在于以下三点：

- n 棵子树的结点中含有n个关键码；
- 所有的叶子结点中包含了全部关键码的信息，及指向含有这些关键码记录的指针，且叶子结点本身依关键码的大小自小而大的顺序链接；
- 非终端结点可以看成是索引部分，结点中仅含有其子树根结点中最大（或最小）关键码。

**数据库索引采用B+树而不是B树的主要原因**：B+树只要遍历叶子节点就可以实现整棵树的遍历，而且在数据库中基于范围的查询是非常频繁的，而B树只能中序遍历所有节点才可以做到遍历整棵树，效率太低。

比较：

红黑树等平衡树也可以用来实现索引，但是文件系统及数据库系统普遍采用 B+ Tree 作为索引结构，主要有以下两个原因：

1. 更少的查找次数

平衡树查找操作的时间复杂度和树高 h 相关，O(h)=O(logdN)，其中 d 为每个节点的出度。

红黑树的出度为 2，而 B+ Tree 的出度一般都非常大，所以红黑树的树高 h 很明显比 B+ Tree 大非常多，查找的次数也就更多。

2. 利用磁盘预读特性

为了减少磁盘 I/O 操作，磁盘往往不是严格按需读取，而是每次都会预读。预读过程中，磁盘进行顺序读取，顺序读取不需要进行磁盘寻道，并且只需要很短的旋转时间，速度会非常快。

操作系统一般将内存和磁盘分割成固定大小的块，每一块称为一页，内存与磁盘以页为单位交换数据。数据库系统将索引的一个节点的大小设置为页的大小，使得一次 I/O 就能完全载入一个节点。并且可以利用预读特性，相邻的节点也能够被预先载入。

**IO次数 取决于B+树的高度h，`h = log(m+1)N`，每个磁盘块的数据项的数量是m，当数据量N一定时，m越大，h越小，m = 磁盘块的大小 / 数据项的大小，磁盘块的大小是固定的，所以如果数据项占的空间越小，数据项的数量越多，树的高度也就越低，这就是为什么每个数据项即索引字段要尽量小，这也是为什么B+树要求把真正的数据放到叶子节点上而不是中间节点，一旦放到中间节点，磁盘块的数据项会大幅下降，导致树增高**

## epool libevent (异步I/O)

[libevent](https://www.cnblogs.com/nearmeng/p/4043548.html)

epoll是一种当文件描述符的内核缓冲区非空的时候，发出可读信号进行通知，当写缓冲区不满的时候，发出可写信号通知的机制

执行epoll_create时，创建了红黑树和就绪链表，执行epoll_ctl时，如果增加socket句柄，则检查在红黑树中是否存在，存在立即返回，不存在则添加到树中，然后向内核注册回调函数，用于句柄对应的中断事件来临时向准备就绪链表中插入句柄。执行epoll_wait时立刻返回准备就绪链表里的句柄即可。

epoll的两种模式，水平触发模式下，只要一个句柄上的事件一次没有处理完，会在以后调用epoll_wait时次次返回这个句柄，而边缘触发模式仅在第一次返回。

- 区别与 select I/O 复用的方式，调用epoll_create()方法 内核就已经在内核态开始准备要监控的句柄，epoll_ctl只是往内核的红黑树中塞入新的句柄，然后注册回调函数用于中断事件向就绪链表中插入数据，做到了一次拷贝，返回时仅仅观察就绪链表中是否有数据即可
- select 和 poll 每次调用都需要将全部描述符从应用进程缓冲区复制到内核缓冲区。
- select 和 poll 的返回结果中没有声明哪些描述符已经准备好，所以如果返回值大于 0 时，应用进程都需要使用轮询的方式来找到 I/O 完成的描述符。epoll_wait将准备就绪的句柄直接返回即可
- 另外，当我们调用epoll_ctl往里塞入百万个句柄时，epoll_wait仍然可以飞快的返回，并有效的将发生事件的句柄给我们用户

libevent是一个轻量级的基于事件驱动的高性能的开源网络库，并且支持多个平台，对多个平台的I/O复用技术进行了封装，屏蔽平台不同导致的差异

Libevent 开发流程：

- 初始化 event_base
- 向 Libevent 添加事件，首先需要设置event对象
- 设置事件ev绑定的文件描述符或者信号，对于定时事件设为-1
- 设置事件类型 `EV_READ | EVPERSIST`
- 设置事件回调函数以及参数arg
- 调用event_base_dispatch(base)开启事件循环

应用场景：

1. select： select 的 timeout 参数精度为 1ns，而 poll 和 epoll 为 1ms，因此 select 更加适用于实时性要求比较高的场景，比如核反应堆的控制。select 可移植性更好，几乎被所有主流平台所支持。
2. poll： poll 没有最大描述符数量的限制，如果平台支持并且对实时性要求不高，应该使用 poll 而不是 select。
3. epoll： 只需要运行在 Linux 平台上，有大量的描述符需要同时轮询，并且这些连接最好是长连接。

需要同时监控小于 1000 个描述符，就没有必要使用 epoll，因为这个应用场景下并不能体现 epoll 的优势。

需要监控的描述符状态变化多，而且都是非常短暂的，也没有必要使用 epoll。因为 epoll 中的所有描述符都存储在内核中，造成每次需要对描述符的状态改变都需要通过 epoll_ctl() 进行系统调用，频繁系统调用降低效率。并且 epoll 的描述符存储在内核，不容易调试

## 布隆过滤器

[bloomFilter](https://blog.csdn.net/xinzhongtianxia/article/details/81294922)

误判率随 Hash 函数个数和存储空间增加成指数级降低 `k = (m/n)ln2`，k为Hash函数个数，n为数据量，m为存储空间大小

参考网上的统计数据：17个Hash函数，2.4亿个Bit位，28MB的存储空间，1000W个元素数据量，误差在千万分之一，我们用了11个Hash函数，28M存储空间，10W数据量，误差在十万分之一到百万分之一之间

- hash表中的槽位越多，越浪费空间，槽位越少，效率越低
- 当样本分布极度不均匀的时候，BitSet会造成很大空间上的浪费，当元素不是整型的时候，BitSet就不适用了

```java
public void set(int value) {
    int byteIndex = value / 8;
    int bitIndex = value % 8;
    byte[byteIndex] = byte[byteIndex] | 1 << (7 - bitIndex)
}
```

- 多个hash，增大随机性，减少hash碰撞的概率
- 扩大数组范围，使hash值均匀分布，进一步减少hash碰撞的概率。
- 要想保持错误率低，最好让位数组有一半还空着。

如果对应的bit位值都为1，那么也不能肯定这个url一定存在，也就是说，BloomFilter其实是存在一定的误判的，这个误判的概率显然和数组的大小以及hash函数的个数以及每个hash函数本身的好坏有关

相比于传统的 List、Set、Map 等数据结构，它更高效、占用空间更少，但是缺点是其返回的结果是概率性的，而不是确切的。

应用场景：黑名单，网络爬虫，K-V系统快速判断某个key是否存在 HBase Redis

```java
private static final int SIZE = 1<<24;
BitSet bitSet = new BitSet(SIZE);
Hash[] hashs = new Hash[8];
private static final int seeds[]=new int[]{3,5,7,9,11,13,17,19};
public static void main(String[] args) {
    String email = "zhenlingcn@126.com";
    BloomDemo bloomDemo = new BloomDemo();
    System.out.println(email+"是否在列表中： "+bloomDemo.contains(email));
    bloomDemo.add(email);
    System.out.println(email+"是否在列表中： "+bloomDemo.contains(email));
    email="zhenlingcn@163.com";
    System.out.println(email+"是否在列表中： "+bloomDemo.contains(email));
}
public BloomDemo() {
    for (int i = 0; i < seeds.length; i++) {
        hashs[i] = new Hash(seeds[i]);
    }
}
public void add(String string) {
    for(Hash hash : hashs) {
        bitSet.set(hash.getHash(string), true);
    }
}
public boolean contains(String string) {
    boolean have = true;
    for(Hash hash : hashs) {
        have &= bitSet.get(hash.getHash(string));
    }
    return have;
}
class Hash {
    private int seed = 0;
    public Hash(int seed) {
        this.seed = seed;
    }
    public int getHash(String string) {
        int val = 0;
        int len = string.length();
        for (int i = 0; i < len; i++) {
            val = val * seed + string.charAt(i);
        }
        return val & (SIZE - 1);
    }
}
```

## 字典树 AC自动机 fail节点 KMP

字典树的典型应用是用于文本词频统计，是一颗多叉树，读入文本的同时建立树，每个节点保存了所有的孩子节点，有标记该节点是否为结束节点，利用字符串的公共前缀来降低查询时间的开销以达到提高效率的目的。空间的花费不会超过单词数×单词长度。

AC自动机是多模匹配算法，就是在Trie的基础上构造失效节点 [参考](https://blog.csdn.net/bestsort/article/details/82947639)

[AC自动机算法详解](https://www.cnblogs.com/cmmdc/p/7337611.html)

- 根据模式串建立Trie
- 给Trie添加失效节点 bfs实现
  - fail指针指向他父亲节点 的 fail指针指向的那个节点 的 具有相同字母的子节点
- 输入待处理文本

```java
private int SIZE = 26;
private TrieNode root;//字典树的根

private Trie() {
    root = new TrieNode();
}

private class TrieNode {
    private int num; //有多少单词通过这个节点,即由根至该节点组成的字符串模式出现的次数
    private TrieNode[]  son;
    private boolean isEnd;
    private char val;

    TrieNode() {
        num = 1;
        son = new TrieNode[SIZE];
        isEnd = false;
    }
}

//建立字典树
public void insert(String str) {
    if(str == null || str.length() == 0) {
        return;
    }
    TrieNode node = root;
    char[] letters = str.toCharArray();
    for(int i = 0, len = str.length(); i < len; i++) {
        int pos = letters[i] - 'a';
        if(node.son[pos] == null) {
            node.son[pos] = new TrieNode();
            node.son[pos].val = letters[i];
        } else {
            node.son[pos].num++;
        }
        node = node.son[pos];
    }
    node.isEnd=true;
}

//在字典树中查找一个完全匹配的单词.
public boolean has(String str) {
    if (str == null || str.length() == 0) {
        return false;
    }
    TrieNode node = root;
    char[] letters = str.toCharArray();
    for (int i = 0,len = str.length(); i<len; i++) {
        int pos = letters[i] - 'a';
        if (node.son[pos] != null) {
            node = node.son[pos];
        } else {
            return false;
        }
    }
    return node.isEnd;
}
```

KMP：KMP算法的思想是，对匹配串本身先做一个处理，得到一个next数组。next 数组各值的含义：代表当前字符之前的字符串中，有多大长度的相同前缀后缀。例如如果 `next[j] = k`，代表 j 之前的字符串中有最大长度为 k 的相同前缀后缀。next 数组相当于“最大长度值” 整体向右移动一位，然后初始值赋为-1

```java
void makeNext(const char P[],int next[]) {
    int q, k;//q:模版字符串下标；k:最大前后缀长度
    int m = strlen(P);//模版字符串长度
    next[0] = 0;//模版字符串的第一个字符的最大前后缀长度为0
    for (q = 1, k = 0; q < m; ++q)//for循环，从第二个字符开始，依次计算每一个字符对应的next值
    {
        while(k > 0 && P[q] != P[k])//递归的求出P[0]···P[q]的最大的相同的前后缀长度k
            k = next[k - 1];          //不理解没关系看下面的分析，这个while循环是整段代码的精髓所在，确实不好理解  
        if (P[q] == P[k])//如果相等，那么最大相同前后缀长度加1
        {
            k++;
        }
        next[q] = k;
    }
}
```

原因在于 `P[k]` 已经和 `P[q]` 失配了，而且 `P[q-k]...P[q-1]` 又与 `P[0]...P[k-1]` 相同，看来 `P[0]...P[k-1]` 这么长的子串是用不了了，那么要找个同样也是 `P[0]` 打头、`P[k-1]` 结尾的子串即 `P[0]...P[j-1](j == next[k-1])`，看看它的下一项 `P[j]` 是否能和 `P[q]` 匹配

```java
int kmp(const char T[],const char P[],int next[])
{
    int n,m;
    int i,q;
    n = strlen(T);
    m = strlen(P);
    makeNext(P,next);
    for (i = 0,q = 0; i < n; ++i)
    {
        while(q > 0 && P[q] != T[i])
            q = next[q - 1];
        if (P[q] == T[i])
        {
            q++;
        }
        if (q == m)
        {
            printf("Pattern occurs with shift:%d\n",(i-m+1));
        }
    }
}
```

函数式编程中的函数这个术语不是指计算机中的函数（实际上是Subroutine），而是指数学中的函数，即自变量的映射。

函数式编程关心数据的映射，命令式编程关心解决问题的步骤

Hadoop 在一次 MapReduce 运算之后，会将数据的运算结果从内存写到磁盘中，第二次MapReduce运算时从磁盘中读取数据，所以瓶颈在2次运算间的多余IO消耗，Spark则是将数据一致缓存在内存中，直到得到最后的结果

Spark Streaming 是核心Spark API 的扩展，可实现对实时数据流的可扩展、高吞吐量、容错流处理

Spark Streaming 接收实时输入数据流并将数据分成批处理，然后由Spark引擎处理以批量生成最终结果流。

```scala
def doTopK1(lines:RDD[String]):Unit = {
    //计算每一个单词的词频
    val wordCountRDD = lines.flatMap(_.split("\\s+")).map((_, 1)).reduceByKey(_+_)
    //排序
    val sorted = wordCountRDD.map{case(key,value) => (value,key)}.sortByKey(true, 3)
    //得到词频最高的4个单词
    val topk = sorted.top(4)
    //print
    topk.foreach(println)
}
```

# 数据库

## 数据库存储过程、触发器

数据库存储过程

SQL语句需要先编译然后执行，而存储过程是在大型数据库系统中，一组为了完成特定功能的SQL 语句集，存储在数据库中，经过第一次编译后调用不需要再次编译，用户通过指定存储过程的名字并给出参数（如果该存储过程带有参数）来执行它。存储过程是数据库中的一个重要对象。

存储过程分为两类：系统提供的存储过程和用户自定义存储过程

优点：

- 重复使用：存储过程可以重复使用，从而可以减少数据库开发人员的工作量
- 提高性能：存储过程在创建的时候就进行了编译，将来使用的时候不用再重新编译。一般的SQL语句每执行一次就需要编译一次，所以使用存储过程提高了效率。
- 减少网络流量：存储过程位于服务器上，调用的时候只需要传递存储过程的名称以及参数就可以了，因此降低了网络传输的数据量。
- 安全性：参数化的存储过程可以防止SQL注入式的攻击，而且可以将Grant、Deny以及Revoke权限应用于存储过程。

```sql
模板：
CREATE  PROCEDURE  存储过程名
        @参数1  数据类型 = 默认值,
        ...,
        @参数n  数据类型 OUTPUT
        AS
        SQL语句
GO

示例：
CREATE PROCEDURE UserLogin
    @name varchar(20),
    @password varchar(20)

AS

-- 定义一个临时用来保存密码的变量
BEGIN
    select * from userinfo where userName=@name and userPass=@password
END
GO

执行：
EXEC 过程名 [参数]
```

触发器

触发器是与表事件相关的特殊的存储过程，它的执行由事件触发，和存储过程的一个区别是触发器不能执行 EXECUTE 语句调用，而是在用户执行 Transact-SQL语句时自动触发执行，经常用于加强数据的完整性约束和业务规则等

- DML 触发器：DML触发器的主要作用在于强制执行业务规则，以及扩展Sql Server约束，默认值等
- DDL 触发器：主要用于审核与规范对数据库中表，触发器，视图等结构上的操作
- 登录触发器

## 数据库范式

- 第一范式：列不可分，eg:【联系人】（姓名，性别，电话），一个联系人有家庭电话和公司电话，那么这种表结构设计就没有达到 1NF；

- 第二范式：有主键，保证完全依赖。eg:订单明细表【OrderDetail】（OrderID，ProductID，UnitPrice，Discount，Quantity，ProductName），Discount（折扣），Quantity（数量）完全依赖（取决）于主键（OderID，ProductID），而 UnitPrice，ProductName 只依赖于 ProductID，不符合2NF；

- 第三范式：无传递依赖(非主键列 A 依赖于非主键列 B，非主键列 B 依赖于主键的情况)，eg:订单表【Order】（OrderID，OrderDate，CustomerID，CustomerName，CustomerAddr，CustomerCity）主键是（OrderID），CustomerName，CustomerAddr，CustomerCity 直接依赖的是 CustomerID（非主键列），而不是直接依赖于主键，它是通过传递才依赖于主键，所以不符合 3NF。

- BC范式：在3NF基础上，主属性不依赖于主属性

五大约束

- primary KEY:设置主键约束
- UNIQUE：设置唯一性约束，不能有重复值
- DEFAULT：默认值约束
- NOT NULL：设置非空约束，该字段不能为空
- FOREIGN key：设置外键约束

事务指的是满足 ACID 特性的一组操作，可以通过 Commit 提交一个事务，也可以使用 Rollback 进行回滚。

## ACID

- 原子性（Atomicity）
  - 事务被视为不可分割的最小单元，事务的所有操作要么全部提交成功，要么全部失败回滚。
- 一致性（Consistency）
  - **数据库**在事务执行前后都保持一致性状态。在一致性状态下，所有事务对一个数据的读取结果都是相同的，应用系统从一个正确的状态到另一个正确的状态，始终满足约束条件。
- 隔离性（Isolation）
  - **一个事务**所做的修改在最终提交以前，对其它事务是不可见的。
- 持久性（Durability）
  - 一旦事务提交，则其所做的修改将会永远保存到数据库中。即使系统发生崩溃，事务执行的结果也不能丢失。使用重做日志来保证持久性。

ACID之间的关系

- 只有满足一致性，事务的执行结果才是正确的。
- 在无并发的情况下，事务串行执行，隔离性一定能够满足。此时只要能满足原子性，就一定能满足一致性。
- 在并发的情况下，多个事务并行执行，事务不仅要满足原子性，还需要满足隔离性，才能满足一致性。
- 事务满足持久化是为了能应对数据库崩溃的情况。

## 并发一致性问题

- 丢失修改：T1 和 T2 两个事务都对一个数据进行修改，T1 先修改，T2 随后修改，T2 的修改覆盖了 T1 的修改。
- 脏读: 事务T1更新了一行记录内容，但并没有提交修改。事务T2读取更新后的行，然后T1执行回滚操作。读取了刚才所做的修改。现在T2读取的行就无效了。（一个事务读取了另一个事务未提交的数据）
- 不可重复读：事务T1读取了一行记录，紧接着T2修改了T1刚才读取的那一行记录，然后T1又再次读取这行记录，发现与刚才读取的结果不同。
- 幻读：事务T1读取一个结果集，然后T2事务在T1结果集范围内插入一行记录。然后T1再次对表进行检索，发现多了T2插入的数据。在连续两次当前读中，第二次的当前读比第一次的当前读返回了更多的记录

产生并发不一致性问题主要原因是破坏了事务的隔离性，解决方法是通过并发控制来保证隔离性，数据库管理系统提供了事务的隔离级别，让用户以一种更轻松的方式处理并发一致性问题。

## 封锁

MySQL 中提供了两种封锁粒度：行级锁以及表级锁

应该尽量只锁定需要修改的那部分数据，而不是所有的资源。锁定的数据量越少，发生锁争用的可能就越小，系统的并发程度就越高。

但是加锁需要消耗资源，锁的各种操作（包括获取锁、释放锁、以及检查锁状态）都会增加系统开销。因此封锁粒度越小，系统开销就越大。

- 读写锁
  - 排他锁：简写为 X 锁，又称写锁。
  - 共享锁：简写为 S 锁，又称读锁。
- 意向锁：可以更容易地支持多粒度封锁。在存在行级锁和表级锁的情况下，事务 T 想要对表 A 加 X 锁，就需要先检测是否有其它事务对表 A 或者表 A 中的任意一行加了锁，那么就需要对表 A 的每一行都检测一次，这是非常耗时的。引入了IS和IX，都是表锁
  - 一个事务在获得**某个数据行对象**的 S 锁之前，必须先获得表的 IS 锁或者更强的锁
  - 一个事务在获得**某个数据行对象**的 X 锁之前，必须先获得表的 IX 锁

封锁协议

两段锁协议(2PL)：MySQL 的 InnoDB 存储引擎采用两段锁协议，会根据隔离级别在需要的时候自动加锁，并且所有的锁都是在同一时刻被释放，这被称为隐式锁定。即锁操作分为两个阶段：加锁阶段与解锁阶段，并且保证加锁阶段与解锁阶段不相交

## 隔离级别

不同的隔离级别对锁的使用是不同的，**锁的应用最终导致不同事务的隔离级别**。

- 读未提交：事务中的修改，即使没有提交，对其它事务也是可见的。会导致脏读
- 读提交：一个事务只能读取已经提交的事务所做的修改。换句话说，一个事务所做的修改在提交之前对其它事务是不可见的。会导致不可重复读、幻读
- 可重复读：保证在同一个事务中多次读取同样数据的结果是一样的。会导致幻读
- 可串行化：强制事务串行执行，会导致加锁读

| | 脏读 | 不可重复读 | 幻读 | 加锁读
| --- | --- | --- | --- | --- |
| 未提交读 | YES | YES | YES | NO |
| 提交读 | NO | YES | YES | NO |
| 可重复读 | NO | NO | YES | NO |
| 可串行化 | NO | NO | NO | YES |

## 多版本并发控制

多版本并发控制是 MySQL 的 InnoDB 存储引擎实现隔离级别的一种具体方式，用于实现提交读和可重复读这两种隔离级别。

版本号：

- 系统版本号：是一个递增的数字，每开始一个新的事务，系统版本号就会自动递增。
- 事务版本号：事务开始时的系统版本号。

MVCC 在每行记录后面都保存了两个隐藏的列，用来存储两个版本号

- 创建版本号：指示创建一个数据行的快照时的系统版本号
- 删除版本号：如果该快照的删除版本号大于当前事务版本号表示该快照有效，否则表示该快照已经被删除了

MVCC 使用到的快照存储在 Undo 日志中，该日志通过回滚指针把一个数据行（Record）的所有快照连接起来。

实现过程：以下实现过程针对可重复读隔离级别。当开始新一个事务时，该事务的版本号肯定会大于当前所有数据行快照的创建版本号，理解这一点很关键。

- SELECT：T 所要读取的数据行快照的创建版本号必须小于 T 的版本号，除此之外，T 所要读取的数据行快照的删除版本号必须大于 T 的版本号
- INSERT：将当前系统版本号作为数据行快照的创建版本号。
- DELETE：将当前系统版本号作为数据行快照的删除版本号。
- UPDATE：将当前系统版本号作为更新前的数据行快照的删除版本号，并将当前系统版本号作为更新后的数据行快照的创建版本号。可以理解为先执行 DELETE 后执行 INSERT。

- 快照读：读取的是记录的可见版本（可能是历史版本），简单的select操作属于快照读，不加锁 `select * from table where ?`
- 当前读：读取的是记录的最新版本，当前读返回的记录都会加上锁，保证其他事务不会再并发修改这条记录，当前读包括 - 特殊的读操作/插入/更新/删除操作，属于当前读，需要加锁。
  - `select * from table where ? lock in share mode`，加共享锁
  - `select * from table where ? for update`，加排他锁
  - `insert into table values (…)`，加排他锁
  - `update table set ? where ?`，加排他锁
  - `delete from table where ?`，加排他锁

Next-Key Locks 是 MySQL 的 InnoDB 存储引擎的一种锁实现。

MVCC 不能解决幻读的问题，Next-Key Locks 就是为了解决这个问题而存在的。在可重复读（REPEATABLE READ）隔离级别下，使用 MVCC + Next-Key Locks 可以解决幻读问题。

## 数据库锁机制

数据库锁定机制简单来说就是数据库为了保证数据的一致性而使各种共享资源在被并发访问，访问变得有序所设计的一种规则，MySQL各存储引擎使用了三种类型（级别）的锁定机制，行级锁定(容易发生死锁)，页级锁定和表级锁定

- InnoDB的行级锁同样分为两种，共享锁和排他锁，同样InnoDB也引入了意向锁（表级锁）的概念，所以也就有了意向共享锁和意向排他锁，所以InnoDB实际上有四种锁，即共享锁（S）、排他锁（X）、意向共享锁（IS）、意向排他锁（IX）
- 在MySQL数据库中，使用表级锁定的主要是MyISAM

- 悲观锁：假定会发生并发冲突，屏蔽一切可能违反数据完整性的操作。加锁的时间可能会很长，这样可能会长时间的限制其他用户的访问，也就是说悲观锁的并发访问性不好
- 乐观锁：假设不会发生并发冲突，只在提交操作时检查是否违反数据完整性。乐观锁不能解决脏读的问题。

### SQL语句锁实例分析

对于 SQL1: `select * from t1 where id = 10` 这条语句而言，在 提交读 和 可重复读 两种隔离级别下，select 操作不加锁，采用快照读

对于 SQL2: `delete from t1 where id = 10` 这条语句而言，加什么锁需要看隔离级别以及id列上存在什么样的索引

#### 提交读 RC 隔离级别下

- **组合一：id列是主键**
  - id是主键时，此SQL只需要在id=10这条记录上加X锁即可
- **组合二：id列是二级唯一索引**
  - 若id列是unique列，其上有unique索引。那么SQL需要加两个X锁，一个对应于id unique索引上的id = 10的记录，另一把锁对应于聚簇索引上的 `[name=’d’(primary key),id=10]` 的记录。
- **组合三：id列是二级非唯一索引**
  - 若id列上有非唯一索引，那么对应的所有满足SQL查询条件的记录，都会被加锁。同时，这些记录在聚簇索引上的记录，也会被加锁。
- **组合四：id列上没有索引**
  - 若id列上没有索引，SQL会走聚簇索引的全扫描进行过滤，由于过滤是由MySQL Server层面进行的。因此每条记录，无论是否满足条件，都会被加上X锁。但是，为了效率考量，MySQL做了优化，对于不满足条件的记录，会在判断后放锁，最终持有的，是满足条件的记录上的锁，但是不满足条件的记录上的加锁/放锁动作不会省略。同时，优化也违背了2PL的约束。

#### 可重复读 RR 隔离级别下

- **组合五：id列是主键**
  - 与组合一相同
- **组合六：id列是二级唯一索引**
  - 与组合二相同
- **组合七：id列是二级非唯一索引**
  - Repeatable Read隔离级别下，id列上有一个非唯一索引，对应SQL：`delete from t1 where id = 10` 首先，通过id索引定位到第一条满足查询条件的记录，加记录上的X锁，加GAP上的GAP锁（前加），然后加主键聚簇索引上的记录X锁，然后返回；然后读取下一条，重复进行。直至进行到第一条不满足条件的记录 `[11,f]`，此时，不需要加记录X锁，但是仍旧需要加GAP锁，最后返回结束。
- **组合八：id列上没有索引**
  - 在Repeatable Read隔离级别下，如果进行全表扫描的当前读，那么会锁上表中的所有记录，同时会锁上聚簇索引内的所有GAP，杜绝所有的并发 更新/删除/插入 操作。当然，也可以通过触发semi-consistent read，来缓解加锁开销与并发影响，但是semi-consistent read本身也会带来其他问题，不建议使用。

#### 串行化 Serializable 隔离级别下

在这种隔离级别下，SQL1 会加读锁，SQL2 和RR隔离级别完全一致

在MySQL/InnoDB中，所谓的读不加锁，并不适用于所有的情况，而是隔离级别相关的。Serializable隔离级别，读不加锁就不再成立，所有的读操作，都是当前读。

复杂的SQL分析：

对于复杂的SQL语句而言，首先要将where条件进行切分，切分为：Index key(索引上的查找范围)，Index Filter(索引上进行过滤)，Table Filter(辅助索引上无法过滤，只能在聚簇索引上过滤)

在Repeatable Read隔离级别下，针对一个复杂的SQL，首先需要提取其where条件。Index Key确定的范围，需要加上GAP锁；Index Filter过滤条件，视MySQL版本是否支持ICP，若支持ICP，则不满足Index Filter的记录，不加X锁，否则需要X锁；Table Filter过滤条件，无论是否满足，都需要加X锁。

死锁分析：

死锁的发生与否，并不在于事务中有多少条SQL语句，死锁的关键在于：两个(或以上)的Session加锁的顺序不一致。而使用本文上面提到的，分析MySQL每条SQL语句的加锁规则，分析出每条语句的加锁顺序，然后检查多个并发SQL间是否存在以相反的顺序加锁的情况，就可以分析出各种潜在的死锁情况，也可以分析出线上死锁发生的原因。

## 存储引擎

不同的存储引擎决定了MySQL数据库中的表可以用不同的方式来存储

### InnoDB

是 MySQL 默认的事务型存储引擎，只有在需要它不支持的特性时，才考虑使用其它存储引擎。

实现了四个标准的隔离级别，默认级别是可重复读（REPEATABLE READ）。在可重复读隔离级别下，通过多版本并发控制（MVCC）+ 间隙锁（Next-Key Locking）防止幻影读。

主索引是聚簇索引，在索引中保存了数据，从而避免直接读取磁盘，因此对查询性能有很大的提升。

内部做了很多优化，包括从磁盘读取数据时采用的可预测性读、能够加快读操作并且自动创建的自适应哈希索引、能够加速插入操作的插入缓冲区等。

支持真正的在线热备份。其它存储引擎不支持在线热备份，要获取一致性视图需要停止对所有表的写入，而在读写混合场景中，停止写入可能也意味着停止读取。

### MyISAM

设计简单，数据以紧密格式存储。对于只读数据，或者表比较小、可以容忍修复操作，则依然可以使用它。

提供了大量的特性，包括压缩表、空间数据索引等。

不支持事务。

不支持行级锁，只能对整张表加锁，读取时会对需要读到的所有表加共享锁，写入时则对表加排它锁。但在表有读取操作的同时，也可以往表中插入新的记录，这被称为并发插入（CONCURRENT INSERT）。

可以手工或者自动执行检查和修复操作，但是和事务恢复以及崩溃恢复不同，可能导致一些数据丢失，而且修复操作是非常慢的。

如果指定了 DELAY_KEY_WRITE 选项，在每次修改执行完成时，不会立即将修改的索引数据写入磁盘，而是会写到内存中的键缓冲区，只有在清理键缓冲区或者关闭表的时候才会将对应的索引块写入磁盘。这种方式可以极大的提升写入性能，但是在数据库或者主机崩溃时会造成索引损坏，需要执行修复操作。

- Memory: 将表中的数据存放在内存中，如果数据库重启或发生崩溃，表中的数据库都将消失，它非常适合存储临时数据的临时表．默认采用哈希索引

比较：

- 事务：InnoDB 是事务型的，可以使用 Commit 和 Rollback 语句。
- 并发：MyISAM 只支持表级锁，而 InnoDB 还支持行级锁。
- 外键：InnoDB 支持外键。
- 备份：InnoDB 支持在线热备份。
- 崩溃恢复：MyISAM 崩溃后发生损坏的概率比 InnoDB 高很多，而且恢复的速度也更慢。
- 其它特性：MyISAM 支持压缩表和空间数据索引（空间数据索引会从所有维度来索引数据，可以有效地使用任意维度来进行组合查询）。

SQL注入：把SQL命令插入到表单提交或输入域名或页面请求的查询字符串，最终达到欺骗服务器执行恶意的SQL命令

- 检验用户输入
- 不使用动态拼装的SQL 参数化SQL
- 每个应用使用单独的权限有限的数据库连接
- hash敏感信息
- 应用异常，模糊提示

## 数据库索引

索引是在存储引擎层实现的，而不是在服务器层实现的，所以不同存储引擎具有不同的索引类型和实现。

### 数据库索引分类

#### B+ Tree 索引

- 因为不再需要进行全表扫描，只需要对树进行搜索即可，所以查找速度快很多。
- 除了用于查找，还可以用于排序和分组。
- 可以指定多个列作为索引列，多个索引列共同组成键。
- 适用于全键值、键值范围或键前缀查找

InnoDB 的 B+Tree 索引分为主索引和辅助索引。主索引的叶子节点 data 域记录着完整的数据记录，这种索引方式被称为聚簇索引。因为无法把数据行存放在两个不同的地方，所以一个表只能有一个聚簇索引。

辅助索引的叶子节点的 data 域记录着主键的值，因此在使用辅助索引进行查找时，需要先查找到主键值，然后再到主索引中进行查找。

#### 哈希索引

哈希索引能以 O(1) 时间进行查找，但是失去了有序性：

- 哈希索引只包含**哈希值和行指针**，不存储字段值，所以不能使用索引来避免读取行
- 无法用于排序与分组
- 只支持精确匹配索引所有列的查询才是有效的，无法用于部分查找和范围查找。

InnoDB 存储引擎有一个特殊的功能叫“自适应哈希索引”，当某个索引值被使用的非常频繁时，会在 B+Tree 索引之上再创建一个哈希索引，这样就让 B+Tree 索引具有哈希索引的一些优点，比如快速的哈希查找。

#### 全文索引

- MyISAM 存储引擎支持全文索引，用于查找文本中的关键词，而不是直接比较是否相等。
- 查找条件使用 MATCH AGAINST，而不是普通的 WHERE。
- 全文索引使用倒排索引实现，它记录着关键词到其所在文档的映射。
- InnoDB 存储引擎在 MySQL 5.6.4 版本中也开始支持全文索引。

### 索引失效、优缺点、优化

建立索引的几大原则：

- 1.最左前缀匹配原则，非常重要的原则，mysql会一直向右匹配直到遇到范围查询(>、<、between、like)就停止匹配
- 2.`=` 和 `in` 可以乱序
- 3.尽量选择区分度高的列作为索引
- 4.索引列不能参与计算
- 5.尽量的扩展索引，不要新建索引

索引优缺点：

- 大大减少了服务器需要扫描的数据行数。
- 帮助服务器避免进行排序和分组，以及避免创建临时表（B+Tree 索引是有序的，可以用于 ORDER BY 和 GROUP BY 操作。临时表主要是在排序和分组过程中创建，因为不需要排序和分组，也就不需要创建临时表）。
- 将随机 I/O 变为顺序 I/O
- 时间方面：创建索引和维护索引要耗费时间，具体地，当对表中的数据进行增加、删除和修改的时候，索引也要动态的维护，这样就降低了数据的维护速度；
- 空间方面：索引需要占物理空间。

怎么发现有问题的SQL语句：

MySQL的慢查询日志是MySQL提供的一种日志记录，它用来记录在MySQL中响应时间超过阀值的语句，具体指运行时间超过long_query_time值的SQL，则会被记录到慢查询日志中。long_query_time的默认值为10，意思是运行10s以上的语句。

EXPLAIN 命令可以对 SELECT 语句进行分析，并输出SELECT 执行的详细信息，以供开发人员针对性优化

SQL语句优化：

- 优化insert语句：一次插入多值
- 应尽量避免在 where 子句中使用!=或<>操作符，否则将引擎放弃使用索引而进行全表扫描；
- 应尽量避免在 where 子句中对字段进行null值判断，否则将导致引擎放弃使用索引而进行全表扫描；

索引优化：

- 独立的列：在进行查询时，索引列不能是表达式的一部分，也不能是函数的参数，否则无法使用索引
- 多列索引：在需要使用多个列作为条件进行查询时，使用多列索引比使用多个单列索引性能更好
- 索引列的顺序：让选择性最强的索引列放在前面
- 前缀索引：对于 BLOB、TEXT 和 VARCHAR 类型的列，必须使用前缀索引，只索引开始的部分字符
- 覆盖索引：索引包含所有需要查询的字段的值。

多列（复合）索引：

对复合索引，按照字段在查询条件中出现的频率建立索引，在复合索引中，记录首先按照第一个字段排序，对第一个字段上取值相同的记录再按照第二个字段的取值排序，依此类推，因此只有复合索引的第一个字段出现在查询条件中，该索引才可能被使用，因此将应用频率高的字段放在复合索引的前面，会使系统最大可能地使用此索引，发挥索引的作用

在mysql建立复合索引时会遵循最左前缀匹配的原则，即最左优先，在检索数据时从联合索引的最左边开始匹配，示例：对列 col1，col2 和 col3 建一个联合索引 `test_col1_col2_col3`

```txt
KEY test_col1_col2_col3 on test(col1, col2, col3)
```

联合索引 test_col1_col2_col3 实际建立了(col1)、(col1,col2)、(col,col2,col3)三个索引。

适合的场景有：

- 全字段匹配
- 匹配部分最左前缀
- 匹配第一列
- 匹配第一列范围查询，可用 like a%，但不能用 like %b
- 精确匹配某一列和范围匹配另外一列

### 索引实现

MyISAM索引实现

- MyISAM索引使用了B+Tree作为索引结构，叶子结点的data域存放的是数据记录的地址。
- MyISAM中索引检索的算法为首先按照B+Tree搜索算法搜索索引，如果指定的Key存在，则取出其data域的值，然后以data域的值为地址，读取相应数据记录。
- 主索引和辅助索引的存储结构没有任何区别。

InnoDB索引实现

- InnoDB 的 B+Tree 索引分为主索引和辅助索引。主索引的叶子节点 data 域记录着完整的数据记录，这种索引方式被称为聚簇索引。因为无法把数据行存放在两个不同的地方，所以一个表只能有一个聚簇索引。
- 辅助索引的叶子节点的 data 域记录着主键的值，因此在使用辅助索引进行查找时，需要先查找到主键值，然后再到主索引中进行查找。
- 适用于全键值、键值范围和键前缀查找，其中键前缀查找只适用于最左前缀查找。如果不是按照索引列的顺序进行查找，则无法使用索引。

### 聚簇索引和非聚簇索引

- 聚簇索引。表数据按照索引的顺序来存储的，也就是说索引项的顺序与表中记录的物理顺序一致。对于聚集索引，叶子结点即存储了真实的数据行，不再有另外单独的数据页。 在一张表上最多只能创建一个聚集索引，因为真实数据的物理顺序只能有一种。
- 非聚簇索引。表数据存储顺序与索引顺序无关。对于非聚集索引，叶结点包含索引字段值及指向数据页数据行的逻辑指针，其行数量与数据表行数据量一致。

- 如果给表中多个字段加上索引， 那么就会出现多个独立的索引结构，每个索引（非聚集索引）互相之间不存在关联
- 每次给字段建一个新索引， 字段中的数据就会被复制一份出来， 用于生成索引。 因此给表添加索索引会增加表的体积，占用磁盘存储空间。

非聚集索引和聚集索引的区别在于，通过聚集索引可以查到需要查找的数据，而通过非聚集索引可以查到记录对应的主键值，再使用主键的值通过聚集索引查找到需要的数据，不管以任何方式查询表，最终都会利用主键通过聚集索引来定位到数据， 聚集索引（主键）是通往真实数据所在的唯一路径。

有一种例外可以不使用聚集索引就能查询出所需要的数据，这种非主流的方法 称之为「覆盖索引」查询，也就是平时所说的复合索引或者多字段索引查询，当为字段建立索引以后，字段中的内容会被同步到索引之中，如果为一个索引指定两个字段，那么这个两个字段的内容都会被同步至索引之中。

## 切分

### 水平切分

水平切分又称为 Sharding，它是将同一个表中的记录拆分到多个结构相同的表中。

当一个表的数据不断增多时，Sharding 是必然的选择，它可以将数据分布到集群的不同节点上，从而缓存单个数据库的压力。

### 垂直切分

垂直切分是将一张表按列切分成多个表，通常是按照列的关系密集程度进行切分，也可以利用垂直切分将经常被使用的列和不经常被使用的列切分到不同的表中。

在数据库的层面使用垂直切分将按数据库中表的密集程度部署到不同的库中，例如将原来的电商数据库垂直切分成商品数据库、用户数据库等。

## 视图

视图是从一个表或是多个表导出的表，视图与表不同，视图是一个虚表，即视图所对应的数据不进行实际存储，数据库中指存储视图的定义，在对视图的数据进行操作时，系统根据视图的定义去操作与视图相关联的基本表。

视图中的数据会随着原表的变化自动更新，因为视图归根结底就是SELECT语句，每次查看视图其实就是执行SELECT语句，因此可以保证数据的最新状态。

使用视图的好处：

- 减少数据冗余，方便对数据的操作
- 数据的安全性和保密

[视图的简单理解](https://blog.csdn.net/zpznba/article/details/86549116)

## Redis

Redis是一款基于内存的且支持持久化、高性能的Key-Value NoSQL 数据库，其支持丰富数据类型(string，list，set，sorted set，hash)，常被用作缓存的解决方案。Redis具有以下显著特点：

- 速度快，因为数据存在内存中，类似于HashMap，HashMap的优势就是查找和操作的时间复杂度都是O(1)；
- 支持丰富数据类型，支持string，list，set，sorted set，hash；
- 支持事务，操作都是原子性，所谓的原子性就是对数据的更改要么全部执行，要么全部不执行；
- 丰富的特性：可用于缓存，消息，按key设置过期时间，过期后将会自动删除。

### 数据结构和对象

#### 简单动态字符串

Redis 只会使用 C 字符串作为字面量， 在大多数情况下， Redis 使用 SDS （Simple Dynamic String，简单动态字符串）作为字符串表示。比起C字符串，SDS字符串由以下优点：

- 尝试复杂度获取字符串长度（len 属性实现）
- 杜绝缓存区溢出（API会先检查SDS的空间是否满足修改所需的要求）
- 减少修改字符串长度时所需的内存重分配次数（空间预分配，惰性空间释放）
- 二进制安全（二进制方式处理SDS存放在buf数组中的数据）
- 兼容部分C字符串函数（遵循C字符串以空字符结尾的惯例）

#### 链表

- 链表被广泛用于实现 Redis 的各种功能， 比如列表键， 发布与订阅， 慢查询， 监视器， 等等。
- 每个链表节点由一个 listNode 结构来表示， 每个节点都有一个指向前置节点和后置节点的指针， 所以 Redis 的链表实现是双端链表。
- 每个链表使用一个 list 结构来表示， 这个结构带有表头节点指针、表尾节点指针、以及链表长度等信息。
- 因为链表表头节点的前置节点和表尾节点的后置节点都指向 NULL ， 所以 Redis 的链表实现是无环链表。
- 通过为链表设置不同的类型特定函数， Redis 的链表可以用于保存各种不同类型的值。

#### 字典

Redis 字典使用哈希表作为底层实现，一个哈希表里面可以有多个哈希表节点， 而每个哈希表节点就保存了字典中的一个键值对。

Redis 中字典 `dict` 包含 `dictht ht[2]`，一般情况下只使用 `ht[0]` 哈希表，`ht[1]` 哈希表只会在对 `ht[0]` 进行rehash时使用

`dict` 包含两个字段 `dictType *type` 和 `void *privdata`

- type 属性是一个指向 dictType 结构的指针， 每个 dictType 结构保存了一簇用于操作特定类型键值对的函数， Redis 会为用途不同的字典设置不同的类型特定函数。如计算哈希值 `hash = dict->type->hashFunction(key)`
- 而 privdata 属性则保存了需要传给那些类型特定函数的可选参数。

Redis 使用 MurmurHash 算法，即使输入的键是有规律的， 算法仍能给出一个很好的随机分布性， 并且算法的计算速度也非常快。

发生Hash碰撞时使用链地址法解决键冲突，为了加快插入速度使用头插

rehash：负载因子 `load_factor = ht[0].used / ht[0].size (已保存节点数量/哈希表大小)`，调整过程为：

1. 为字典的 `ht[1]` 哈希表分配空间， 这个哈希表的空间大小取决于要执行的操作， 以及 `ht[0]` 当前包含的键值对数量 （也即是 ht[0].used 属性的值）：
    - 如果执行的是扩展操作， 那么 `ht[1]` 的大小为第一个大于等于 `ht[0]`.used * 2 的 2^n （2 的 n 次方幂）；
    - 如果执行的是收缩操作， 那么 `ht[1]` 的大小为第一个大于等于 `ht[0]`.used 的 2^n 。
2. 将保存在 `ht[0]` 中的所有键值对 rehash 到 `ht[1]` 上面： rehash 指的是重新计算键的哈希值和索引值， 然后将键值对放置到 `ht[1]` 哈希表的指定位置上。
3. 当 `ht[0]` 包含的所有键值对都迁移到了 `ht[1]` 之后 （`ht[0]` 变为空表）， 释放 `ht[0]` ， 将 `ht[1]` 设置为 `ht[0]` ， 并在 `ht[1]` 新创建一个空白哈希表， 为下一次 rehash 做准备。

这个rehash过程不是一次性、集中式地完成的，而是分多次，渐进式地完成的，通过 `rehashidx` 索引计数器，设置为0 表示rehash工作开始了，-1表示rehash操作完成了，在rehash进行期间，每次对字典的操作程序除了执行指定的操作以外， 还会顺带将 `ht[0]` 哈希表在 rehashidx 索引上的所有键值对 rehash 到 `ht[1]` ， 当 rehash 工作完成之后， 程序将 rehashidx 属性的值增一。

因为在进行渐进式 rehash 的过程中， 字典会同时使用 `ht[0]` 和 `ht[1]` 两个哈希表， 所以在渐进式 rehash 进行期间， 字典的删除（delete）、查找（find）、更新（update）等操作会在两个哈希表上进行，新添加到字典的键值对一律会被保存到 `ht[1]` 中，而 `ht[0]` 不再进行任何添加操作，这一措施保证了 `ht[0]` 包含的键值对数量会只减不增， 并随着 rehash 操作的执行而最终变成空表。

#### 跳跃表

跳跃表（skiplist）是一种有序数据结构， 它通过在每个节点中维持多个指向其他节点的指针， 从而达到快速访问节点的目的。Redis 只在两个地方用到了跳跃表， 一个是实现有序集合键， 另一个是在集群节点中用作内部数据结构

跳跃表节点：

- **层**：跳跃表节点的 level 数组可以包含多个元素， 每个元素都包含一个指向其他节点的指针， 程序可以通过这些层来加快访问其他节点的速度， 一般来说， 层的数量越多， 访问其他节点的速度就越快
- **前进指针**：每个层都有一个指向表尾方向的前进指针（level[i].forward 属性）， 用于从表头向表尾方向访问节点。
- **跨度**：的跨度（level[i].span 属性）用于记录两个节点之间的距离，跨度实际上是用来计算排位的，在查找某个节点的过程中， 将沿途访问过的所有层的跨度累计起来， 得到的结果就是目标节点在跳跃表中的排位。
- **后退指针**：节点的后退指针（backward 属性）用于从表尾向表头方向访问节点：跟可以一次跳过多个节点的前进指针不同， 因为每个节点只有一个后退指针， 所以每次只能后退至前一个节点。
- **分值和成员**：分值（score 属性）是一个 double 类型的浮点数， 跳跃表中的所有节点都按分值从小到大来排序。节点的成员对象（obj 属性）是一个指针， 它指向一个字符串对象， 而字符串对象则保存着一个 SDS 值。

#### 整数集合

- 整数集合是集合键的底层实现之一。
- 整数集合的底层实现为数组， 这个数组以有序、无重复的方式保存集合元素， 在有需要时， 程序会根据新添加元素的类型， 改变这个数组的类型。
- 升级操作为整数集合带来了操作上的灵活性， 并且尽可能地节约了内存。
- 整数集合只支持升级操作， 不支持降级操作。

#### 压缩列表

压缩列表是一种为节约内存而开发的顺序型数据结构。压缩列表被用作列表键和哈希键的底层实现之一。

一个压缩列表可以包含任意多个节点（entry）， 每个节点可以保存一个字节数组或者一个整数值。每个压缩列表节点都由 `previous_entry_length`（前一个节点的长度）、`encoding`（节点的content属性保存数据的类型和长度）、`content`（节点的值） 三个部分组成

| previous_entry_length | encoding | content | 解释 |
| --- | --- | --- | --- |
| 1字节表示前一个节点的长度小于254字节 | 00001011 | "hello world" | 00表示节点保存的是一个字节数组，001011 记录了字节数组的长度 11
| 5字节表示前一个节点的长度大于254字节 | 11000000 | 10086 | 11000000 表示节点保存的是一个 int16_t 类型的整型值，content属性保存着节点的值 10086

#### 对象

Redis 并没有直接使用这些数据结构来实现键值对数据库， 而是基于这些数据结构创建了一个对象系统，这个系统包含字符串对象、列表对象、哈希对象、集合对象和有序集合对象这五种类型的对象， 每种对象都用到了至少一种我们前面所介绍的数据结构。

Redis 使用对象来表示数据库中的键和值， 每次当我们在 Redis 的数据库中新创建一个键值对时， 我们至少会创建两个对象， 一个对象用作键值对的键（键对象）， 另一个对象用作键值对的值（值对象）。

```c++
typedef struct redisObject {

    unsigned type:4;    // 类型
    unsigned encoding:4;  // 编码
    void *ptr; // 指向底层实现数据结构的指针

    // ...
} robj;
```

对于 Redis 数据库保存的键值对来说， 键总是一个字符串对象， 而值则可以是字符串对象、列表对象、哈希对象、集合对象或者有序集合对象的其中一种

| 对象 | 对象 type 属性的值 | TYPE 命令的输出 |
| --- | --- | --- |
| 字符串对象 | REDIS_STRING | "string" |
| 列表对象 | REDIS_LIST | "list" |
| 哈希对象 | REDIS_HASH | "hash" |
| 集合对象 | REDIS_SET | "set"
| 有序集合对象 | REDIS_ZSET | "zset" |

encoding 属性记录了对象所使用的编码， 也即是说这个对象使用了什么数据结构作为对象的底层实现

| 对象所使用的底层数据结构 | 编码常量 | OBJECT ENCODING 命令输出 |
| --- | --- | --- |
| 整数 | EDIS_ENCODING_INT | "int" |
| 编码的简单动态字符串 | REDIS_ENCODING_EMBSTR | "embstr" |
| 简单动态字符串 | REDIS_ENCODING_RAW | "raw" |
| 字典 | EDIS_ENCODING_HT | "hashtable" |
| 双端链表 | REDIS_ENCODING_LINKEDLIST | "linkedlist" |
| 压缩列表 | REDIS_ENCODING_ZIPLIST | "ziplist" |
| 整数集合 | REDIS_ENCODING_INTSET | "intset" |
| 跳跃表和字典 | REDIS_ENCODING_SKIPLIST | "skiplist" |

# Linux

## I/O 模式

两个阶段：

- 等待数据准备好
- 从内核向进程复制数据

对于一个套接字上的输入操作，第一步通常涉及等待数据从网络中到达。当所等待数据到达时，它被复制到内核中的某个缓冲区。第二步就是把数据从内核缓冲区复制到应用进程缓冲区。

[IO - 同步，异步，阻塞，非阻塞 （亡羊补牢篇）](https://blog.csdn.net/historyasamirror/article/details/5778378)

[也谈IO模型](http://www.rowkey.me/blog/2016/01/18/io-model/)

### 阻塞I/O

应用进程被阻塞，直到数据从内核缓冲区复制到应用进程缓冲区中才返回。

应该注意到，在阻塞的过程中，其它应用进程还可以执行，因此阻塞不意味着整个操作系统都被阻塞。因为其它应用进程还可以执行，所以不消耗 CPU 时间，这种模型的 CPU 利用率效率会比较高。

### 非阻塞I/O

应用进程执行系统调用之后，内核返回一个错误码。应用进程可以继续执行，但是需要不断的执行系统调用来获知 I/O 是否完成，这种方式称为轮询（polling）。

由于 CPU 要处理更多的系统调用，因此这种模型的 CPU 利用率比较低。

### I/O复用

使用 select 或者 poll 等待数据，并且可以等待多个套接字中的任何一个变为可读。这一过程会被阻塞，当某一个套接字可读时返回，之后再使用 recvfrom 把数据从内核复制到进程中。

它可以让单个进程具有处理多个 I/O 事件的能力。又被称为 Event Driven I/O，即事件驱动 I/O。

如果一个 Web 服务器没有 I/O 复用，那么每一个 Socket 连接都需要创建一个线程去处理。如果同时有几万个连接，那么就需要创建相同数量的线程。相比于多进程和多线程技术，I/O 复用不需要进程线程创建和切换的开销，系统开销更小。

### 信号驱动I/O

应用进程使用 sigaction 系统调用，内核立即返回，应用进程可以继续执行，也就是说等待数据阶段应用进程是非阻塞的。内核在数据到达时向应用进程发送 SIGIO 信号，应用进程收到之后在信号处理程序中调用 recvfrom 将数据从内核复制到应用进程中。

相比于非阻塞式 I/O 的轮询方式，信号驱动 I/O 的 CPU 利用率更高。

### 异步I/O

应用进程执行 aio_read 系统调用会立即返回，应用进程可以继续执行，不会被阻塞，内核会在所有操作完成之后向应用进程发送信号。

异步 I/O 与信号驱动 I/O 的区别在于，异步 I/O 的信号是通知应用进程 I/O 完成，而信号驱动 I/O 的信号是通知应用进程可以开始 I/O。

### 对比

- 同步IO和异步IO 的区别反映在数据拷贝阶段是由用户线程完成还是内核完成。所以说异步IO必须要有操作系统的底层支持。
- 阻塞IO和非阻塞IO 的区别反映在IO操作的第一个阶段，即查看数据是否就绪时，是如何处理的。

多路复用IO为何比非阻塞IO模型的效率高是因为在非阻塞IO中，不断地询问socket状态时通过用户线程去进行的，而在多路复用IO中，轮询每个socket状态是内核在进行的，这个效率要比用户线程要高的多。

在异步IO模型中，IO操作的两个阶段都不会阻塞用户线程，这两个阶段都是由内核自动完成，然后发送一个信号告知用户线程操作已完成。用户线程中不需要再次调用IO函数进行具体的读写。这点是和信号驱动模型有所不同的，在信号驱动模型中，当用户线程接收到信号表示数据已经就绪，然后需要用户线程调用IO函数进行实际的读写操作；而在异步IO模型中，收到信号表示IO操作已经完成，不需要再在用户线程中调用iO函数进行实际的读写操作。

两种高性能IO设计模式：Reactor和Proactor

- 在Reactor模式中，会先对每个client注册感兴趣的事件，然后有一个线程专门去轮询每个client是否有事件发生，当有事件发生时，便顺序处理每个事件，当所有事件处理完之后，便再转去继续轮询
- 在Proactor模式中，当检测到有事件发生时，会新起一个异步操作，然后交由内核线程去处理，当内核线程完成IO操作之后，发送一个通知告知操作已完成

**synchronous IO和asynchronous IO**:

- A synchronous I/O operation causes the requesting process to be blocked until that **I/O operation** completes
  - blocking IO
  - non-blocking IO
  - IO multiplexing
- An asynchronous I/O operation does not cause the requesting process to be blocked;

## 内存管理

进程内存空间5个不同的数据区

- 代码段：代码段是用来存放可执行文件的操作指令，也就是说是它是可执行程序在内存中的镜像
- 数据段：数据段用来存放可执行文件中已初始化全局变量
- BSS段：BSS段包含了程序中未初始化的全局变量，在内存中 bss段全部置零
- 堆：堆是用于存放进程运行中被动态分配的内存段，它的大小并不固定，可动态扩张或缩减
- 栈：栈是用户存放程序临时创建的局部变量

Linux操作系统采用虚拟内存管理技术，使得每个进程都有各自互不干涉的进程地址空间，该空间是块大小为4G的线性虚拟空间，用户所看到和接触到的都是该虚拟地址，无法看到实际的物理内存地址，用户空间从0到3G（0xC0000000），内核空间占据3G到4G，每个进程的用户空间是完全独立、互不相干的

进程内存管理的对象是进程线性地址空间上的内存镜像，这些内存镜像其实就是进程使用的虚拟内存区域，虚拟空间被划分为许多大小可变的内存区域 - 4096的倍数

在Linux内核中对应进程内存区域的数据结构是: `vm_area_struct`, **内核将每个内存区域作为一个单独的内存对象管理**，相应的操作也都一致，`vm_area_struct` 是描述进程地址空间的基本管理单元，对于一个进程来说往往需要多个内存区域来描述它的虚拟空间，这些内存区域可以使用红黑树或者链表关联

由虚变实：

从上面已经看到进程所能直接操作的地址都为虚拟地址。当进程需要内存时，从内核获得的仅仅是虚拟的内存区域，而不是实际的物理地址，进程并没有获得物理内存，获得的仅仅是对一个新的线性地址区间的使用权。实际的物理内存只有当进程真的去访问新获取的虚拟地址时，才会由“请求页机制”产生“缺页”异常，从而进入分配实际页面的例程。

该异常是虚拟内存机制赖以存在的基本保证——它会告诉内核去真正为进程分配物理页，并建立对应的页表，这之后虚拟地址才实实在在地映射到了系统的物理内存上。

Linux内核管理物理内存是通过分页机制实现的，它将整个内存划分成无数个4k（在i386体系结构中）大小的页，从而分配和回收内存的基本单位便是内存页了

### Buddy分配算法

伙伴的定义：两个块大小相同，两个块地址连续，两个块必须是同一个大块中分离出来的

缺点：一个很小的块往往会阻碍一个大块的合并，一个系统中，对内存块的分配，大小是随机的，一片内存中仅一个小的内存块没有释放，旁边两个大的就不能合并。

分配原理：

假如系统需要 4 个页面大小的内存块，该算法就到 `free_area[2]` 中查找，如果链表中有空闲块，就直接从中摘下并分配出去。如果没有，算法将顺着数组向上查找 `free_area[3]`,如果 `free_area[3]` 中有空闲块，则将其从链表中摘下，分成等大小的两部分，前四个页面作为一个块插入`free_area[2]`，后4个页面分配出去，`free_area[3]`中也没有，就再向上查找，如果`free_area[4]`中有，就将这16个页面等分成两份，前一半挂到 `free_area[3]` 的链表头部，后一半的8个页等分成两等分，前一半挂 `free_area[2]` 的链表中，后一半分配出去。假如 `free_area[4]` 也没有，则重复上面的过程，知道到达 `free_area` 数组的最后，如果还没有则放弃分配。

释放原理：

内存的释放是分配的逆过程，也可以看作是伙伴的合并过程。当释放一个块时，先在其对应的链表中考查是否有伙伴存在，如果没有伙伴块，就直接把要释放的块挂入链表头；如果有，则从链表中摘下伙伴，合并成一个大块，然后继续考察合并后的块在更大一级链表中是否有伙伴存在，直到不能合并或者已经合并到了最大的块

整个过程中，位图扮演了重要的角色，位图的某一位对应两个互为伙伴的块，为1表示其中一块已经分配出去了，为0表示两块都空闲。伙伴中无论是分配还是释放都只是相对的位图进行异或操作。分配内存时对位图的运算是为释放过程服务，释放过程根据位图判断伙伴是否存在，如果对相应位的异或操作得1，则没有伙伴可以合并，如果异或操作得0，就进行合并，并且继续按这种方式合并伙伴，直到不能合并为止。

### 吞吐和响应

首先我们在思考调度器的时候，我们要理解任何操作系统的调度器设计只追求2个目标：吞吐率大和延迟低

- 因为吞吐率要大，势必要把更多的时间放在做真实的有用功，而不是把时间浪费在频繁的进程上下文切换
- 而延迟要低，势必要求优先级高的进程可以随时抢占进来，打断别人，强行插队。但是，抢占会引起上下文切换，上下文切换的时间本身对吞吐率来讲，是一个消耗

在Linux运行的进程，分为2类，一类是CPU消耗型（狂算），一类是I/O消耗型（狂睡，等I/O），前者CPU利用率高，后者CPU利用率低。一般而言，I/O消耗型任务对延迟比较敏感，应该被优先调度

系统调用是操作系统的最小功能单位，内核向上层应用提供访问的接口

内核从本质上看是一种软件——控制计算机的硬件资源，并提供上层应用程序运行的环境，用户态即上层应用程序的活动空间，应用程序的执行必须依托于内核提供的资源

库函数实现对系统调用的封装，将简单的业务逻辑结构呈现给用户，方便用户调用

用户态到内核态切换

- 系统调用 (软中断)
- 异常事件
- 外围设备的中断 (硬中断)

孤儿进程：一个父进程退出，而它的一个或多个子进程还在运行，那么那些子进程将成为孤儿进程。孤儿进程将被init进程(进程号为1)所收养，并由init进程对它们完成状态收集工作。

僵尸进程：一个进程使用fork创建子进程，如果子进程退出，而父进程并没有调用wait或waitpid获取子进程的状态信息，那么子进程的进程描述符仍然保存在系统中。这种进程称之为僵死进程。

进程死锁四个必要条件：

- 互斥条件: 一个资源每次只能被一个进程使用。
- 请求与保持条件: 一个进程因请求资源而阻塞时，对已获得的资源保持不放。
- 不剥夺条件: 进程已获得的资源，在末使用完之前，不能强行剥夺。
- 循环等待条件: 若干进程之间形成一种头尾相接的循环等待资源关系。

银行家算法通过先 试探 分配给该进程资源，然后通过安全性算法判断分配后的系统是否处于安全状态，若不安全则试探分配作废，让该进程继续等待。

进程和线程的区别：

1. 进程是资源分配的最小单位，线程是CPU调度的最小单位，这句话的意思是 进程仍然可以被CPU调度，而资源分配必须在进程上分配
2. 一个进程可以有多个线程
3. 进程的创建和销毁的开销要大于线程
4. 进程间共享资源依赖于共享文件或者共享内存，同一进程的不同线程间可以共享进程的资源
5. 进程的个体间是完全独立的，而线程间是彼此依存的。多进程环境中，任何一个进程的终止，不会影响到其他进程。而多线程环境中，父线程终止，全部子线程被迫终止(没有了资源)。而任何一个子线程终止一般不会影响其他线程
6. fork()是将父进程的全部资源复制给了子进程。而线程的clone只是复制了一小部分必要的资源
7. Linux中 进程和线程上下文切换的开销没有太大差别

进程调度算法：

批处理系统：批处理系统没有太多的用户操作，在该系统中，调度算法目标是保证吞吐量和周转时间（从提交到终止的时间）

- 先来先服务
- 短作业优先
- 最短剩余时间优先

交互式系统：交互式系统有大量的用户交互操作，在该系统中调度算法的目标是快速地进行响应。

- 时间片轮转
- 优先级调度
- 多机反馈队列

实时系统：实时系统要求一个请求在一个确定时间内得到响应。分为硬实时和软实时，前者必须满足绝对的截止时间，后者可以容忍一定的超时。

### 硬链接和软链接

链接简单说实际上是一种文件共享的方式

- 软链接： `ln -s source target`，在硬盘上创建新的 inode 以及 区块，区块内容为目标文件的绝对路径，访问时用绝对路径替换即可。当源文件被删除了，区块中的绝对路径失效，软链接就打不开了。可以为目录建立链接。
- 硬链接： `ln source target`，inode 指向目标文件在硬盘中的区块，删除目标文件仍可以访问，不能跨越文件系统、不能对目录进行链接，因为会破坏文件系统的有向无环的结构

读取文件数据时需要经过目录的 `inode` 和 `block`，然后才能够找到文件的 inode 号，最终才会读到正确的 文件block 内的数据

目录inode（满足权限？） => 目录block => 档案inode（满足权限？） => 档案block

# 其他

## SIP协议

SIP是一个应用层的信令控制协议。用于创建、修改和释放一个或多个参与者的会话

- **用户代理：** UA 如用于创建和管理 SIP 会话的移动电话、多媒体手持设备、PC、PDA 等。用户代理客户机发出消息。用户代理服务器对消息进行响应。
- **注册服务器：** SIP 注册服务器是包含域中所有用户代理的位置的数据库。在 SIP 通信中，这些服务器会检索出对方的 IP 地址和其他相关信息，并将其发送到 SIP 代理服务器。
- **代理服务器：** SIP 代理服务器接受 SIP UA 的会话请求并查询 SIP 注册服务器，获取收件方 UA 的地址信息。然后，它将会话邀请信息直接转发给收件方 UA（如果它位于同一域中）或代理服务器（如果 UA 位于另一域中）。
- **重定向服务器：** SIP 重定向服务器允许 SIP 代理服务器将 SIP 会话邀请信息定向到外部域。SIP 重定向服务器可以与 SIP 注册服务器和 SIP 代理服务器同在一个硬件上。

注册阶段：

- 用户首次试呼时，终端代理A 向代理服务器发送REGISTER 注册请求；
- 代理服务器通过后端认证中心获知用户信息不在数据库中，便向终端代理回送401Unauthorized 质询信息，其中包含安全认证所需的令牌；
- 终端代理提示用户输入其标识和密码后，根据安全认证令牌将其加密后，再次用REGISTER 消息报告给代理服务器；
- 代理服务器将REGISTER 消息中的用户信息解密，通过认证/计费中心验证其合法后，将该用户信息登记到数据库中，并向终端代理A 返回成功响应消息200 OK。

呼叫建立阶段：

- 发送到代理服务器的INVITE请求负责启动会话。
- 代理服务器发送100 尝试立即响应呼叫者（Alice）以停止INVITE请求的重新发送。
- 代理服务器在位置服务器中搜索Bob的地址。获取地址后，进一步转发INVITE请求。
- 此后，Bob手机生成的180 振铃（临时响应）返回给爱丽丝。
- 鲍勃拿起手机后一个200 OK响应很快产生。
- 一旦200 OK到达Alice，Bob 从Alice 收到一个ACK。
- 同时，会话建立，RTP数据包（会话）从两端开始流动。
- 会话结束后，任何参与者（Alice或Bob）都可以发送一个BYE请求来终止会话。
- BYE直接从Alice到Bob绕过代理服务器。
- 最后，Bob发送200 OK响应来确认BYE，会话终止。

## Web请求

- DHCP配置主机信息：假设主机最开始没有 IP 地址以及其它信息，那么就需要先使用 DHCP 来获取。
- ARP解析MAC地址：主机通过浏览器生成一个 TCP 套接字，套接字向 HTTP 服务器发送 HTTP 请求。为了生成该套接字，主机需要知道网站的域名对应的 IP 地址。
- DNS解析域名：DNS客户机端向DNS服务器端发送一份查询报文，报文中包含着要访问的主机名字段，该DNS客户机最终会收到一份回答报文，其中包含有该主机名对应的IP地址，一旦该浏览器收到来自DNS的IP地址，就可以向该IP地址定位的HTTP服务器发起TCP连接
- HTTP请求页面：有了 HTTP 服务器的 IP 地址之后，主机就能够生成 TCP 套接字，该套接字将用于向 Web 服务器发送 HTTP GET 报文。

DNS 解析过程：

- 首先查询本地DNS缓存，查看是否由 指定域名对应的IP
- 向服务提供商的DNS服务器发起查询
- 如果没有 `ISP-DNS` 向根域名服务器发出请求 根域名服务器返回 `com` 域的NS记录
- `ISP-DNS` 向 `com` 域的服务器发送请求 返回 `baidu.com` 这个域的NS记录
- `ISP-DNS` 向 `baidu.com` 域的权威服务器发起请求，查了下有 `www` 这台主机，把这个IP返回
- `ISP-DNS` 拿到IP返回给客户端，并保存在缓存中

## GET 和 POST 区别

- GET 用于获取资源，而 POST 用于传输实体主体，可以用来提交或取回消息。
- GET 和 POST 的请求都能使用额外的参数，但是 GET 的参数是以查询字符串出现在 URL 中，而 POST 的参数存储在实体主体中。不能因为 POST 参数存储在实体主体中就认为它的安全性更高，因为照样可以通过一些抓包工具（Fiddler）查看。GET方法提交的URL参数数据大小没有限制是指http协议没有对URL长度进行限制，这个限制是特定的浏览器及服务器对它的限制
- 请求报文的 HTTP 方法本身是可缓存的，包括 GET 和 HEAD，但是 PUT 和 DELETE 不可缓存，POST 在多数情况下不可缓存的。
- 在使用 XMLHttpRequest 的 POST 方法时，浏览器会先发送 Header 再发送 Data。但并不是所有浏览器会这么做，例如火狐就不会。而 GET 方法 Header 和 Data 会一起发送。

## Cookie 和 Session

HTTP 协议是无状态的，主要是为了让 HTTP 协议尽可能简单，使得它能够处理大量事务。HTTP/1.1 引入 Cookie 来保存状态信息。

Cookie 是服务器发送到用户浏览器并保存在本地的一小块数据，它会在浏览器之后向同一服务器再次发起请求时被携带上，用于告知服务端两个请求是否来自同一浏览器。

除了可以将用户信息通过 Cookie 存储在用户浏览器中，也可以利用 Session 存储在服务器端，存储在服务器端的信息更加安全。

Session是在服务端保存的一个数据结构，用来跟踪用户的状态，这个数据可以保存在集群、数据库、文件中；Cookie是客户端保存用户信息的一种机制，用来记录用户的一些信息，也是实现Session的一种方式。

使用 Session 维护用户登录状态的过程如下：

- 用户进行登录时，用户提交包含用户名和密码的表单，放入 HTTP 请求报文中；
- 服务器验证该用户名和密码，如果正确则把用户信息存储到 Redis 中，它在 Redis 中的 Key 称为 Session ID；
- 服务器返回的响应报文的 Set-Cookie 首部字段包含了这个 Session ID，客户端收到响应报文之后将该 Cookie 值存入浏览器中；
- 客户端之后对同一个服务器进行请求时会包含该 Cookie 值，服务器收到之后提取出 Session ID，从 Redis 中取出用户信息，继续之前的业务操作。

应该注意 Session ID 的安全性问题，不能让它被恶意攻击者轻易获取，那么就不能产生一个容易被猜到的 Session ID 值。此外，还需要经常重新生成 Session ID，在对安全性要求极高的场景下，例如转账等操作，除了使用 Session 管理用户状态之外，还需要对用户进行重新验证，比如重新输入密码，或者使用短信验证码等方式。

Cookie 和 Session 选择：

- Cookie 只能存储 ASCII 码字符串，而 Session 则可以存取任何类型的数据，因此在考虑数据复杂性时首选 Session；
- Cookie 存储在浏览器中，容易被恶意查看。如果非要将一些隐私数据存在 Cookie 中，可以将 Cookie 值进行加密，然后在服务器进行解密；
- 对于大型网站，如果用户所有的信息都存储在 Session 中，那么开销是非常大的，因此不建议将所有的用户信息都存储到 Session 中。

## 数字认证

服务器的运营人员向 CA 提出公开密钥的申请，CA 在判明提出申请者的身份之后，会对已申请的公开密钥做数字签名，然后分配这个已签名的公开密钥，并将该公开密钥放入公开密钥证书后绑定在一起。

进行 HTTPS 通信时，服务器会把证书发送给客户端。客户端取得其中的公开密钥之后，先使用数字签名进行验证，如果验证通过，就可以开始通信了。

- Bob 将自己的公钥和 Bob 的一系列信息发送给CA，CA使用CA的密钥签名形成证书
- Bob计算要传输文件的Hash值，将Hash值用 Bob 的私钥加密，得到摘要，将摘要，Bob的证书，和文件一同发送给 Alice
- 客户端A收到 Bob 发来的摘要，证书和 文件 之后，先从获取 CA的公钥 对证书解密，从中拿到 Bob 的公钥，然后解密摘要，得到一个Hash1，然后对文件进行Hash，得到Hash2，比较Hash值1和2，如果相同则证明证书有效，双方开始通信

Alice不用维护公钥库

- 客户端随机生成对称密钥key，用服务器端的公钥加密key，发送给服务器端，服务器端用私钥解密得到key，双方便可以用key加密要传输的数据了

HTTPS的攻击方式：中间人攻击，首先中间人可以获取到客户端与服务器之间所有的通信内容，对客户端而言中间人是一个服务器，对服务器而言中间人是一个客户端，解决办法，客户端预埋证书，只有证书验证通过以后才可以通信

## 路由分组转发

- 从数据报的首部提取目的主机的 IP 地址 D，得到目的网络地址 N。
- 若 N 就是与此路由器直接相连的某个网络地址，则进行直接交付；
- 若路由表中有目的地址为 D 的特定主机路由，则把数据报传送给表中所指明的下一跳路由器；
- 若路由表中有到达网络 N 的路由，则把数据报传送给路由表中所指明的下一跳路由器；
- 若路由表中有一个默认路由，则把数据报传送给路由表中所指明的默认路由器；
- 报告转发分组出错。

路由选择协议：

RIP 是一种基于距离向量的路由选择协议。距离是指跳数，直接相连的路由器跳数为 1。跳数最多为 15，超过 15 表示不可达。

RIP 按固定的时间间隔仅和相邻路由器交换自己的路由表，经过若干次交换之后，所有路由器最终会知道到达本自治系统中任何一个网络的最短距离和下一跳路由器地址。

开放最短路径优先 OSPF：

- 向本自治系统中的所有路由器发送信息，这种方法是洪泛法。
- 发送的信息就是与相邻路由器的链路状态，链路状态包括与哪些路由器相连以及链路的度量，度量用费用、距离、时延、带宽等来表示。
- 只有当链路状态发生变化时，路由器才会发送信息。
- 所有路由器都具有全网的拓扑结构图，并且是一致的，相比于 RIP，OSPF 的更新过程收敛的很快。

## Reactor模式

Reactor 模式是一种处理一个或多个客户端并发交付服务请求的事件设计模式，ServiceHandler 复用传入的请求，并将它们同步分派给关联的请求处理程序

Reactor 四个角色：

- 初始化分配器(Initiation Dispatcher)：EventHandler的容器，用来注册、移除EventHandler等，另外它作为Reactor模式的入口调用同步事件分离器等待事件发生，当事件发生时，将事件发生的Handle分发到相应的EventHandler上
- Handle：句柄或文件描述符，对资源的一种抽象
- 同步事件分离器(Synchronous Event Demultiplexer)：系统调用，用于等待事件的发生，在Linux下为 select，poll，epoll，Java NIO中为 Selector
- 事件处理器(Event Handler)：本身由多个回调方法构成，定义了事件处理的方法

Reactor 流程：

1. 主程序初始化 InitationDispatcher，注册 EventHandler 到 InitationDispatcher中，每个 EventHandler 包含对相应 Handle 的引用，从而建立 Handle 到 EventHandler 的映射。
2. 主程序调用 InitiationDispatcher 的 handle_events() 方法以启动 Event Loop，在 Event Loop 中，调用同步事件分离器的方法等待事件发生。
3. 当某个或某些事件发生后，同步事件分离器的方法返回对应的 Handle，InitiationDispatcher 根据返回的 Handle 找到注册的 EventHandler，并回调该 EventHandler 的 handle_events(event_type) 方法。
4. 在 EventHandler 的 handle_events(event_type) 方法中还可以向 InitiationDispatcher 中注册新的 Eventhandler，比如对 AcceptorEventHandler 来说，当有新的 client 连接时，它会产生新的 EventHandler 以处理新的连接，并注册到 InitiationDispatcher 中。
